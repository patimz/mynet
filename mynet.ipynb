{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "directed-adoption",
   "metadata": {},
   "source": [
    "In this notebook we will build an artificial neural net from scratch which will be trained on the [MNIST dataset](http://yann.lecun.com/exdb/mnist/) containing hand-written digits 0-9. We will access the dataset through [keras](keras.io)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial-iceland",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "twelve-stations",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(x, y), (x_val, y_val) = mnist.load_data()\n",
    "x = tf.keras.utils.normalize(x, axis=1)\n",
    "x_val = tf.keras.utils.normalize(x_val, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adult-completion",
   "metadata": {},
   "source": [
    "Each data point in _**x**_ is a 28x28 matrix whose elements correspond to the intensity on a gray scale. Each matrix is paired with a label which we store in _**y**_. This is what one data point looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "welcome-professor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<matplotlib.image.AxesImage at 0x103cd4350>, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x[7], cmap=plt.cm.binary), y[7]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "offshore-ethernet",
   "metadata": {},
   "source": [
    "We will leave only 3's and 7's. We will also turn the labels into booleans (i.e. 1 for '3', 0 for '7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "driving-panel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12396, 28, 28), 12396)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_3vs7 = np.array([yi for yi in y if yi==3 or yi==7])\n",
    "y_3vs7bin = np.array([1 if yi==3 else 0 for yi in y_3vs7])\n",
    "x_3vs7 = np.array([xi for xi, yi in zip(x, y) if yi==3 or yi==7])\n",
    "y_val_3vs7 = np.array([yi for yi in y_val if yi==3 or yi==7])\n",
    "y_val_3vs7bin = np.array([1 if yi==3 else 0 for yi in y_val_3vs7])\n",
    "x_val_3vs7 = np.array([xi for xi, yi in zip(x_val, y_val) if yi==3 or yi==7])\n",
    "x_3vs7.shape, len(y_3vs7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infinite-lebanon",
   "metadata": {},
   "source": [
    "We will flatten the last two dimensions so that 28x28 matrices will be 784-element-long vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "understood-horizontal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12396, 784)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_3vs7_2d = x_3vs7.reshape(-1, 28*28)\n",
    "x_3vs7_2d.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dutch-career",
   "metadata": {},
   "source": [
    "Our simple neural net will contain one layer with a linear function **xb** x **weights** + **bias** where we also apply `sigmoid` in order to transform the output to (0,1) interval. In the second layer, if the transformed output is greater than 0.5 the image is considered to be of '3', otherwise - '7'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "sunrise-diving",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNet:\n",
    "    def __init__(self, size, mu=0, std=1.0):        \n",
    "        self.weights = np.random.normal(mu, std, size)\n",
    "        self.bias = np.random.normal(mu, std, 1)\n",
    "        \n",
    "    def update_parameters(self, weights_grad, bias_grad, lr):\n",
    "        self.weights -= weights_grad*lr\n",
    "        self.bias -= bias_grad*lr        \n",
    "    \n",
    "    def linear(self, x):\n",
    "        return x@self.weights + self.bias\n",
    "        \n",
    "    def sigmoid(self, x): return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    # first layer of the net\n",
    "    def predict(self, x):\n",
    "        return self.sigmoid(self.linear(x))\n",
    "    \n",
    "    # final layer of the net whith two states (either 3 or 7)\n",
    "    def is3(self, x):\n",
    "        if len(x) == 1:\n",
    "            if self.predict(x)>0.5:\n",
    "                print(\"Yes, it's 3\")\n",
    "            else:\n",
    "                print(\"No, it's 7\")\n",
    "        else:\n",
    "            print(\"Multiple images selected\")        \n",
    "        \n",
    "    def accuracy(self, x, labels):\n",
    "        correct = (self.predict(x)>0.5) == labels\n",
    "        return correct.mean()    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outside-playlist",
   "metadata": {},
   "source": [
    "The loss function of our prediction. It measures the margin of our predictions against the targets (labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "wired-canal",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_loss(model, x, targets):\n",
    "    preds = model.predict(x)\n",
    "    loss = np.array([1-p if t==1 else p for p, t in zip(preds, targets)])\n",
    "    return loss.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statutory-transmission",
   "metadata": {},
   "source": [
    "In order to find an optimal set of model parameters (weights & bias) we need to determine the behavior of the loss function subject to change in model parameters. Such a behavior is quantified by what is known as _gradient_. To find the gradient, we need to calculate the derivative at each element of the vector **weights** and **bias**. We will use a finite-difference approximation for the derivative of a function **f**: \n",
    "\n",
    "(**f**(**model_parameters**+**dx**) - **f**(**model_parameters**-**dx**)) / (2***dx**),\n",
    "\n",
    "where **dx**=0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "honey-carry",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_loss_grad(model, batch, labels):\n",
    "    dx = 0.001\n",
    "    old_bias = model.bias.item()\n",
    "    model.bias = old_bias + dx\n",
    "    loss_up = mnist_loss(model, batch, labels)\n",
    "    model.bias = old_bias - dx\n",
    "    loss_down = mnist_loss(model, batch, labels)\n",
    "    bias_grad = (loss_up - loss_down)/2/dx\n",
    "    model.bias = np.array([old_bias])\n",
    "    \n",
    "    N = len(model.weights)\n",
    "    weights_grad = np.zeros(N)\n",
    "    for i in range(N):\n",
    "        old_weight = model.weights[i].item() # saving the weight\n",
    "        model.weights[i] = old_weight + dx\n",
    "        loss_up = mnist_loss(model, batch, labels)\n",
    "        model.weights[i] = old_weight - dx\n",
    "        loss_down = mnist_loss(model, batch, labels)  \n",
    "        weights_grad[i] = (loss_up - loss_down)/2/dx\n",
    "        model.weights[i] = old_weight # returning to the old value       \n",
    "    \n",
    "    return weights_grad, bias_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "computational-ratio",
   "metadata": {},
   "source": [
    "Now that we have a gradient we can start training our model. We will update the model parameters like so\n",
    "\n",
    "**parameters** -= **gradient** x **lr**,\n",
    "\n",
    "where **lr** is a learning rate. This operation is implemented in `MyNet` component function `update_parameters`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "flying-sauce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(data, model, lr=1., batch_size=100):\n",
    "    x, y = data\n",
    "    for b in range(batch_size):\n",
    "        index_range = slice(b*batch_size,(b+1)*batch_size)\n",
    "        batch = x[index_range]\n",
    "        labels = y[index_range]\n",
    "        \n",
    "        weights_grad, bias_grad = mnist_loss_grad(model, batch, labels)\n",
    "        model.update_parameters(weights_grad, bias_grad, lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agricultural-perspective",
   "metadata": {},
   "source": [
    "The function above will take in the following required parameters: data - (x,y) tuple; model - (`MyNet` object). After we trained the model, we should estimate how well our predictions are. We will do that via `MyNet` component function `accuracy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "olympic-water",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fit(train_data, test_data, model, epochs):\n",
    "    x, y = test_data\n",
    "    print(\"accuracy before training:\", model.accuracy(x, y))\n",
    "    for epoch in range(epochs):        \n",
    "        train_epoch(train_data, model)\n",
    "        print(\"epoch\", epoch+1, \", accuracy:\", model.accuracy(x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "serial-strip",
   "metadata": {},
   "source": [
    "We will split our data into a training and testing set. The usual practice is such about 80% is used for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "another-forest",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = 9917 # about 80% of the original set\n",
    "train_data = x_3vs7_2d[:ind], y_3vs7bin[:ind]\n",
    "test_data = x_3vs7_2d[ind:], y_3vs7bin[ind:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proprietary-conservative",
   "metadata": {},
   "source": [
    "Creating a `MyNet` object and initializing it to 784 random initial weights + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "opposite-seven",
   "metadata": {},
   "outputs": [],
   "source": [
    "mynet = MyNet(28*28)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "revised-coverage",
   "metadata": {},
   "source": [
    "Training the model for 3 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "stunning-supervisor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy before training: 0.49415086728519564\n",
      "epoch 1 , accuracy: 0.9233561920129084\n",
      "epoch 2 , accuracy: 0.9499798305768455\n",
      "epoch 3 , accuracy: 0.9576442113755547\n"
     ]
    }
   ],
   "source": [
    "model_fit(train_data, test_data, mynet, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "double-cathedral",
   "metadata": {},
   "source": [
    "After we achieved a satisfactory accuracy, let's see how our model is able to recognize the images. We will pick an arbitrary image from x_val_3vs7 data set which was not part of our training or testing set so the model never saw it. `MyNet` component function `is3` is implementing the final layer of the neural net, where the question \"Is this 3?\" is asked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "digital-underwear",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, it's 3\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_ind = 125 # try a different image here\n",
    "plt.imshow(x_val_3vs7[x_ind], cmap=plt.cm.binary)\n",
    "mynet.is3(x_val_3vs7[x_ind].reshape(-1, 28*28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outdoor-monaco",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
